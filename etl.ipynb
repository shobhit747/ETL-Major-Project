{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abc368-881d-4916-9930-03bb33714de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import time\n",
    "import psutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "from transform import transform_chunk\n",
    "\n",
    "\n",
    "def _write_parquet(df: pd.DataFrame, out_dir: Path, chunk_id: int) -> Path:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fname = out_dir / f\"chunk_{chunk_id:07d}_{uuid.uuid4().hex}.parquet\"\n",
    "    df.to_parquet(fname, index=False)\n",
    "    return fname\n",
    "\n",
    "\n",
    "def _process_and_write(chunk: pd.DataFrame, chunk_id: int, config) -> Path:\n",
    "    df_t = transform_chunk(\n",
    "        chunk,\n",
    "        required_cols=config.REQUIRED_COLUMNS,\n",
    "        dtypes=config.DTYPES,\n",
    "        enable_features=config.ENABLE_FEATURES,\n",
    "        drop_duplicates=config.DROP_DUPLICATES,\n",
    "        drop_na_rows=config.DROP_NA_ROWS\n",
    "    )\n",
    "    return _write_parquet(df_t, config.PARQUET_DIR, chunk_id)\n",
    "\n",
    "\n",
    "def extract_chunks(input_file: Path, chunk_size: int, dtypes=None):\n",
    "    # Iterator yields dataframes per chunk\n",
    "    reader = pd.read_csv(input_file, chunksize=chunk_size, dtype=dtypes, low_memory=False)\n",
    "    for i, chunk in enumerate(reader):\n",
    "        yield i, chunk\n",
    "\n",
    "\n",
    "def load_merged(parquet_dir: Path, merged_parquet_path: Path) -> Path:\n",
    "    # Merge all parquet parts into single parquet file\n",
    "    parts = sorted(parquet_dir.glob(\"chunk_*.parquet\"))\n",
    "    if not parts:\n",
    "        raise FileNotFoundError(f\"No parquet chunks found in {parquet_dir}\")\n",
    "    df = pd.concat((pd.read_parquet(p) for p in parts), ignore_index=True)\n",
    "    df.to_parquet(merged_parquet_path, index=False)\n",
    "    return merged_parquet_path\n",
    "\n",
    "\n",
    "def run_pipeline(config):\n",
    "    start_time = time.perf_counter()\n",
    "    os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Collect system metrics baseline\n",
    "    cpu_start = psutil.cpu_percent(interval=None)\n",
    "    mem_start = psutil.virtual_memory().percent\n",
    "\n",
    "    futures = []\n",
    "    written_files = []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=config.MAX_WORKERS) as executor:\n",
    "        for chunk_id, chunk in extract_chunks(config.INPUT_FILE, config.CHUNK_SIZE, dtypes=config.DTYPES):\n",
    "            futures.append(executor.submit(_process_and_write, chunk, chunk_id, config))\n",
    "\n",
    "        for fut in as_completed(futures):\n",
    "            written_files.append(fut.result())\n",
    "\n",
    "    merged_path = None\n",
    "    if config.WRITE_MERGED_PARQUET:\n",
    "        merged_path = load_merged(config.PARQUET_DIR, config.MERGED_PARQUET)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    cpu_end = psutil.cpu_percent(interval=None)\n",
    "    mem_end = psutil.virtual_memory().percent\n",
    "\n",
    "    metrics = {\n",
    "        \"chunks_written\": len(written_files),\n",
    "        \"merged_output\": str(merged_path) if merged_path else None,\n",
    "        \"elapsed_seconds\": round(end_time - start_time, 3),\n",
    "        \"cpu_percent_start\": cpu_start,\n",
    "        \"cpu_percent_end\": cpu_end,\n",
    "        \"mem_percent_start\": mem_start,\n",
    "        \"mem_percent_end\": mem_end,\n",
    "    }\n",
    "    return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
